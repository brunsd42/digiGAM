{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6625ed9-7791-4b39-96ce-ae5abe5eabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565af35f-b06e-40dc-a523-0a38c1867a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_GAM2025 import gam_info\n",
    "\n",
    "import test_functions \n",
    "import functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bbad62-50cf-4d0a-b9b1-4cd14b226aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "platformID = 'WSC'\n",
    "# country\n",
    "pop_size_col = 'Population Size (We are social)'\n",
    "pop_size_col = 'Population2020'\n",
    "\n",
    "country_codes_cols = ['PlaceID', pop_size_col]\n",
    "country_codes = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='CountryID')[country_codes_cols]\n",
    "\n",
    "# week \n",
    "week_tester = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='GAM Period',)\n",
    "week_tester['w/c'] = pd.to_datetime(week_tester['w/c'])\n",
    "\n",
    "service_tester = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='ServiceID',)\n",
    "service_hierarchy = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='Service Hierarchy',)\n",
    "\n",
    "platform_tester = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='PlatformID',)\n",
    "\n",
    "overlap_SocWebOverlap = pd.read_excel(\"helper/Final Overlaps 2021.xlsx\", sheet_name='SocWebOverlap').drop(columns=['Population 2020']).drop_duplicates()\n",
    "overlap_SocWebOverlap['PlaceID'] = overlap_SocWebOverlap['PlaceID'].replace('MYT', 'MAY').replace('WLF', 'WFI')\n",
    "#overlap_SocWebOverlap = overlap_SocWebOverlap.merge(country_codes, on='PlaceID', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fbb7f-e591-48ca-a5fa-ae78f6f67857",
   "metadata": {},
   "source": [
    "# functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c618a5f-2b3d-44c0-9d33-7676c3944d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_reach(df, services, label, pop_size_col, country_codes, deal_with_zero=True, \n",
    "                          calc_type='sainsbury'):\n",
    "    \"\"\"\n",
    "    Filters, merges, aggregates, and applies the Sainsbury formula to compute combined reach.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Source DataFrame with weekly reach data.\n",
    "    services (list): List of ServiceIDs to include.\n",
    "    label (str): Label to assign to the resulting ServiceID.\n",
    "    pop_size_col (str): Column name for population size.\n",
    "    country_codes (pd.DataFrame): Mapping DataFrame for PlaceID enrichment.\n",
    "    deal_with_zero (bool): Whether to apply shortcut logic in the formula.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Aggregated and transformed DataFrame with combined reach.\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['ServiceID'].isin(services)].merge(country_codes, on='PlaceID', how='left')\n",
    "    \n",
    "    pivot_df = pd.crosstab(\n",
    "        index=[filtered_df['PlaceID'], filtered_df[pop_size_col], \n",
    "               filtered_df['w/c']],\n",
    "        columns=filtered_df['ServiceID'],\n",
    "        values=filtered_df['Reach'],\n",
    "        aggfunc='sum'\n",
    "    ).reset_index().fillna(0)\n",
    "\n",
    "    if calc_type == 'add':\n",
    "        pivot_df['Reach'] = pivot_df[services].sum(axis=1)\n",
    "    elif calc_type == 'sainsbury':\n",
    "        pivot_df = functions.sainsbury_formula(pivot_df, pop_size_col, services, \n",
    "                                               'Reach', deal_with_zero=deal_with_zero)\n",
    "        \n",
    "    else: \n",
    "        print('error')\n",
    "        \n",
    "    pivot_df['ServiceID'] = label\n",
    "    return pivot_df[['w/c', 'ServiceID', 'PlaceID', 'Reach']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb9ce3-cc2e-463a-aec6-7fec3d294a4b",
   "metadata": {},
   "source": [
    "# ingestion \n",
    "\n",
    "## workflow 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70af4ba-68fa-487d-9908-5cee4f4aed3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_AX2byCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                          | 1/30 [00:01<00:31,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_FOAbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                         | 2/30 [00:02<00:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_GNLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 3/30 [00:03<00:26,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_EN2byCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▊                                      | 4/30 [00:04<00:26,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TWI_GNLbyCountry.xlsx\n",
      "Valid file: GAM2025_WEEKLY_YT-_ANWbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 6/30 [00:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_ANYbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████▎                                 | 7/30 [00:05<00:17,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_TOTbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▋                                | 8/30 [00:06<00:18,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_WSLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████▎                            | 10/30 [00:30<01:53,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_WORbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████▊                           | 11/30 [00:31<01:25,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_ALLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 12/30 [00:32<01:05,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_MA-byCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▋                        | 13/30 [00:32<00:46,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_ENGbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████                       | 14/30 [00:33<00:36,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_ALLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 15/30 [00:34<00:28,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_MA-byCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████▉                    | 16/30 [00:34<00:20,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_ANYbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▎                  | 17/30 [00:35<00:17,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_ANWbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 18/30 [00:36<00:13,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_TOTbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████▏               | 19/30 [00:37<00:10,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_WSLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 20/30 [00:38<00:11,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_WORbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 21/30 [00:39<00:09,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_GNLbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████▌           | 22/30 [00:40<00:07,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_WSEbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████▉          | 23/30 [00:40<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_AX2byCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 24/30 [00:41<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_AXEbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████▊       | 25/30 [00:42<00:04,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_YT-_ENWbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████▎     | 26/30 [00:43<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file: GAM2025_WEEKLY_TTK_AXEbyCountry.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [00:44<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "weekly_folder = \"../data/singlePlatform/output/weekly/\"\n",
    "singlePlatform_df_list = []\n",
    "\n",
    "valid_platforms = set(platform_tester['PlatformID']) \n",
    "valid_services = set(service_tester['ServiceID'])| {'WSL'}\n",
    "            \n",
    "for file in tqdm(os.listdir(weekly_folder)):\n",
    "    if file == \".DS_Store\" or \"podcast\" in file.lower() or \"site\" in file.lower():\n",
    "        continue\n",
    "    parts = file.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        platform_id = parts[2]\n",
    "        service_id = parts[3].replace(\"byCountry.xlsx\", \"\")\n",
    "        \n",
    "        if (platform_id in valid_platforms) and (service_id in valid_services):\n",
    "            print(f\"Valid file: {file}\")\n",
    "            file_path = os.path.join(weekly_folder, file)\n",
    "            temp = pd.read_excel(file_path)\n",
    "            temp['w/c'] = pd.to_datetime(temp['w/c'])\n",
    "            temp['source'] = file\n",
    "            singlePlatform_df_list.append(temp)\n",
    "\n",
    "singlePlatform_df_raw = pd.concat(singlePlatform_df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a12b9-832a-4a07-818d-f91543241845",
   "metadata": {},
   "source": [
    "# processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e039d-e6c7-480d-b939-6479f83220c6",
   "metadata": {},
   "source": [
    "## test columns (& remove total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd3e46f-47c7-414d-99db-09b712e615e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing PlaceID: _merge\n",
      "both          550384\n",
      "left_only          0\n",
      "right_only         0\n",
      "Name: count, dtype: int64\n",
      "Unmatched PlaceIDs: []\n",
      "\n",
      "Missing w/c: _merge\n",
      "both          550384\n",
      "left_only          0\n",
      "right_only         0\n",
      "Name: count, dtype: int64\n",
      "Unmatched w/cs: <DatetimeArray>\n",
      "[]\n",
      "Length: 0, dtype: datetime64[ns]\n",
      "\n",
      "Missing PlatformID: _merge\n",
      "both          550384\n",
      "left_only          0\n",
      "right_only         0\n",
      "Name: count, dtype: int64\n",
      "Unmatched PlatformIDs: []\n",
      "\n",
      "Missing ServiceID: _merge\n",
      "both          550384\n",
      "left_only          0\n",
      "right_only         0\n",
      "Name: count, dtype: int64\n",
      "Unmatched ServiceIDs: []\n",
      "Rows with zero or missing Reach: 5877\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "def test_merge(df, tester_df, key, label):\n",
    "    merged = df.merge(tester_df, on=key, how='left', indicator=True)\n",
    "    print(f\"\\nMissing {label}:\", merged['_merge'].value_counts())\n",
    "    print(f\"Unmatched {label}s:\", merged[merged['_merge'] == 'left_only'][key].unique())\n",
    "    return merged[merged['_merge'] == 'both'].drop(columns=['_merge'])\n",
    "\n",
    "singlePlatform_df = test_merge(singlePlatform_df_raw, country_codes, 'PlaceID', 'PlaceID')\n",
    "singlePlatform_df = test_merge(singlePlatform_df, week_tester, 'w/c', 'w/c')\n",
    "singlePlatform_df = test_merge(singlePlatform_df, platform_tester, 'PlatformID', 'PlatformID')\n",
    "singlePlatform_df = test_merge(singlePlatform_df, service_tester, 'ServiceID', 'ServiceID')\n",
    "\n",
    "reach_issues = singlePlatform_df[(singlePlatform_df['Reach'] == 0) | (singlePlatform_df['Reach'].isna())]\n",
    "print(\"Rows with zero or missing Reach:\", reach_issues.shape[0])\n",
    "\n",
    "duplicates = singlePlatform_df[singlePlatform_df.duplicated(subset=['ServiceID', 'PlatformID', 'PlaceID', 'w/c'])]\n",
    "print(\"Duplicate rows:\", duplicates.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc3f0f-f8a1-43b1-9427-45277a4177ec",
   "metadata": {},
   "source": [
    "## workflow 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0691cb-6325-485f-8349-a849ccf6d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_service_df = pd.crosstab(\n",
    "        index=[ singlePlatform_df['PlaceID'], \n",
    "                singlePlatform_df['w/c'], \n",
    "                singlePlatform_df['ServiceID']],\n",
    "        columns=singlePlatform_df['PlatformID'],\n",
    "        values= singlePlatform_df['Reach'],\n",
    "        aggfunc='sum'\n",
    "    ).reset_index().fillna(0)\n",
    "\n",
    "full_service_df = full_service_df.merge(country_codes, on='PlaceID', how='left', )\n",
    "full_service_df.head()\n",
    "cols = full_service_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0f0bd-c763-42e3-bd61-15501bcc4d02",
   "metadata": {},
   "source": [
    "### WSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb09e60-4b4a-4a16-a539-7dfa3be0cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PlaceID', 'w/c', 'ServiceID', 'TTK', 'TWI', 'YT-', 'Population2020',\n",
       "       'Tapestry Market', 'Country Name', 'FB & YT Factor',\n",
       "       'Own Web & Social Factor', 'Web', 'Facebook Incremental',\n",
       "       'YouTube Incremental', 'Social Incremental if YouTube bigger',\n",
       "       'Social Incremental if Facebook bigger', 'Social Incremental',\n",
       "       '% Twitter', '% Instagram', '% socialdedup Factor', 'Unnamed: 15',\n",
       "       'Unnamed: 16', '_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove MA / WOR and agg services \n",
    "exclude_ids = ['WOR', 'MA-', \n",
    "               'ENG', 'EN2', 'ENW', \n",
    "               'ANW', 'TOT', 'AX2', 'ANY', 'ALL', ]\n",
    "weekly_ws_df = full_service_df[~full_service_df['ServiceID'].isin(exclude_ids)]\n",
    "\n",
    "# add overlaps\n",
    "weekly_ws_df = weekly_ws_df.merge(overlap_SocWebOverlap, on='PlaceID', how='left', indicator=True)\n",
    "weekly_ws_df.ServiceID.unique()\n",
    "weekly_ws_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8d22a-e453-4f46-ab79-66faee0f7b21",
   "metadata": {},
   "source": [
    "Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86fbfff0-54e9-4f1b-a510-a968585a1160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBE missing!\n",
      "INS missing!\n",
      "TEL missing!\n",
      "WEI missing!\n"
     ]
    }
   ],
   "source": [
    "# Define expected platform columns\n",
    "platform_cols = ['FBE', 'INS', 'TWI', 'YT-', 'TTK', 'TEL', 'WEI']\n",
    "                \n",
    "# Add missing columns with default value 0\n",
    "for col in platform_cols:\n",
    "    if col not in weekly_ws_df.columns:\n",
    "        print(f'{col} missing!')\n",
    "        weekly_ws_df[col] = 0\n",
    "        \n",
    "# Step 1: Calculate Max Reach\n",
    "weekly_ws_df['Max Reach'] = weekly_ws_df[platform_cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3051851-4c05-47f7-8e42-a8ba72deb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Identify Max Platform\n",
    "def get_max_platform(row):\n",
    "    if row['Max Reach'] == row['FBE']:\n",
    "        return 'Facebook'\n",
    "    elif row['Max Reach'] == row['YT-']:\n",
    "        return 'YouTube'\n",
    "    elif row['Max Reach'] == row['TWI']:\n",
    "        return 'Twitter'\n",
    "    elif row['Max Reach'] == row['TTK']:\n",
    "        return 'Tiktok'\n",
    "    else:\n",
    "        return 'Instagram'\n",
    "\n",
    "weekly_ws_df['Max Platform'] = weekly_ws_df.apply(get_max_platform, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1469f8a0-3e87-44bc-8ca8-9c38813db023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate WSC1\n",
    "def calculate_wsc1(row):\n",
    "    if row['Max Platform'] == 'Facebook':\n",
    "        return (row['FBE'] + row['YT-'] * row['YouTube Incremental'] +\n",
    "                row['INS'] * row['% Instagram'] +\n",
    "                row['TWI'] * row['% Twitter'] +\n",
    "                0.28 * row['TTK'])\n",
    "    elif row['Max Platform'] == 'YouTube':\n",
    "        return (row['YT-'] + row['FBE'] * row['Facebook Incremental'] +\n",
    "                row['INS'] * row['% Instagram'] +\n",
    "                row['TWI'] * row['% Twitter'] +\n",
    "                0.28 * row['TTK'])\n",
    "    elif row['Max Platform'] == 'Instagram':\n",
    "        return (row['INS'] + row['YT-'] * row['YouTube Incremental'] +\n",
    "                row['FBE'] * 0.03030303 +\n",
    "                0.28 * row['TTK'])\n",
    "    elif row['Max Platform'] == 'Tiktok':\n",
    "        return (row['TTK'] + row['YT-'] * row['YouTube Incremental'] +\n",
    "                row['INS'] * row['% Instagram'] +\n",
    "                row['TWI'] * row['% Twitter'] +\n",
    "                row['FBE'] * row['Facebook Incremental'])\n",
    "    else:  # Twitter\n",
    "        return (row['TWI'] + row['YT-'] * row['YouTube Incremental'] +\n",
    "                row['INS'] * row['% Instagram'] +\n",
    "                row['FBE'] * row['Facebook Incremental'])\n",
    "\n",
    "weekly_ws_df[f'{platformID}1'] = weekly_ws_df.apply(calculate_wsc1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc1cd8-92ba-4d33-b111-1980b24a8dca",
   "metadata": {},
   "source": [
    "Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "842dac28-546b-43c9-ab55-e269ed735db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all required columns exist, fill missing ones with 0\n",
    "required_cols = ['FBE', 'YT-', 'INS', 'TWI', 'TTK', 'WEI', 'TEL', '% socialdedup Factor']\n",
    "for col in required_cols:\n",
    "    if col not in weekly_ws_df.columns:\n",
    "        print(f'{col} missing!')\n",
    "        weekly_ws_df[col] = 0\n",
    "\n",
    "# Calculate WSC2\n",
    "weekly_ws_df[f'{platformID}2'] = (\n",
    "    (weekly_ws_df['FBE'] + weekly_ws_df['YT-'] + weekly_ws_df['INS'] + weekly_ws_df['TWI']) * weekly_ws_df['% socialdedup Factor']\n",
    "    + 0.28 * weekly_ws_df['TTK']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09ea88-522b-4bf6-a321-67926249684f",
   "metadata": {},
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa23e2a1-6fa5-498f-b34b-5bde2c44d6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w/c</th>\n",
       "      <th>PlaceID</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Reach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>ARA</td>\n",
       "      <td>859.991595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AXE</td>\n",
       "      <td>51803.551760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AZE</td>\n",
       "      <td>2.763772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>BEN</td>\n",
       "      <td>12.841184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>BUR</td>\n",
       "      <td>7.664414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         w/c PlaceID ServiceID         Reach\n",
       "0 2024-04-01     AFG       ARA    859.991595\n",
       "1 2024-04-01     AFG       AXE  51803.551760\n",
       "2 2024-04-01     AFG       AZE      2.763772\n",
       "3 2024-04-01     AFG       BEN     12.841184\n",
       "4 2024-04-01     AFG       BUR      7.664414"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure all required columns exist\n",
    "required_cols = [f'{platformID}1', f'{platformID}2', 'FBE', 'YT-', 'INS', 'TWI', 'TTK', 'WEI', 'TEL']\n",
    "for col in required_cols:\n",
    "    if col not in weekly_ws_df.columns:\n",
    "        print(f'{col} missing!')\n",
    "        weekly_ws_df[col] = 0\n",
    "\n",
    "# Compute WSC Final\n",
    "def compute_wsc_final(row):\n",
    "    wsc1 = row[f'{platformID}1']\n",
    "    wsc2 = row[f'{platformID}2']\n",
    "    if (\n",
    "        wsc2 < wsc1 or\n",
    "        wsc2 < row['FBE'] or\n",
    "        wsc2 < row['YT-'] or\n",
    "        wsc2 < row['INS'] or\n",
    "        wsc2 < row['TWI'] or\n",
    "        wsc2 < row['TTK']\n",
    "    ):\n",
    "        return wsc1\n",
    "    else:\n",
    "        return wsc2\n",
    "\n",
    "weekly_ws_df['Reach'] = weekly_ws_df.apply(compute_wsc_final, axis=1)\n",
    "weekly_ws_df = weekly_ws_df[['w/c', 'PlaceID', 'ServiceID', 'Reach']]\n",
    "weekly_ws_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e74450-15dd-4054-8c82-8e1b5a1ebe1b",
   "metadata": {},
   "source": [
    "### MA & Studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc248535-61e1-4401-927d-a1ed0d8357e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBE missing!\n",
      "INS missing!\n",
      "WEI missing!\n",
      "TEL missing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/pq5c3fbj5rs1tz_5w1hycq4h0000gn/T/ipykernel_5863/2876689785.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ma_wor_df[col] = 0\n",
      "/var/folders/gz/pq5c3fbj5rs1tz_5w1hycq4h0000gn/T/ipykernel_5863/2876689785.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ma_wor_df[col] = 0\n",
      "/var/folders/gz/pq5c3fbj5rs1tz_5w1hycq4h0000gn/T/ipykernel_5863/2876689785.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ma_wor_df[col] = 0\n",
      "/var/folders/gz/pq5c3fbj5rs1tz_5w1hycq4h0000gn/T/ipykernel_5863/2876689785.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ma_wor_df[col] = 0\n",
      "/Users/brunsd01/BBC Dropbox/Domi Bruns/Audience Insight/GAM 2025/7. GAM25_calculation/3 DigiGAM/code/functions.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df.apply(calculate_formula, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w/c</th>\n",
       "      <th>PlaceID</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Reach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>WOR</td>\n",
       "      <td>4588.206711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>AFG</td>\n",
       "      <td>WOR</td>\n",
       "      <td>5157.029512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>AFG</td>\n",
       "      <td>WOR</td>\n",
       "      <td>5317.983034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>AFG</td>\n",
       "      <td>WOR</td>\n",
       "      <td>5866.918630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>AFG</td>\n",
       "      <td>WOR</td>\n",
       "      <td>6581.134325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           w/c PlaceID ServiceID        Reach\n",
       "39  2024-04-01     AFG       WOR  4588.206711\n",
       "80  2024-04-08     AFG       WOR  5157.029512\n",
       "121 2024-04-15     AFG       WOR  5317.983034\n",
       "165 2024-04-22     AFG       WOR  5866.918630\n",
       "209 2024-04-29     AFG       WOR  6581.134325"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_wor_df = full_service_df[full_service_df['ServiceID'].isin(['WOR', 'MA-'])]\n",
    "required_cols = ['FBE', 'YT-', 'INS', 'TWI', 'TTK', 'WEI', 'TEL']\n",
    "for col in required_cols:\n",
    "    if col not in ma_wor_df.columns:\n",
    "        print(f'{col} missing!')\n",
    "        ma_wor_df[col] = 0\n",
    "\n",
    "ma_wor_df = functions.sainsbury_formula(ma_wor_df, pop_size_col, \n",
    "                                        required_cols, \n",
    "                                        'Reach')\n",
    "\n",
    "weekly_ma_wor_df = ma_wor_df[['w/c', 'PlaceID', 'ServiceID', 'Reach']]\n",
    "weekly_ma_wor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec14267-eb76-4bda-a4e9-895f4880705d",
   "metadata": {},
   "source": [
    "prep the aggregate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ea090e-a149-4f9e-828b-5fac2c4fd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df = pd.concat([weekly_ws_df, weekly_ma_wor_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f83f75-3e4e-410c-aa9e-b3338c757bcb",
   "metadata": {},
   "source": [
    "### ENW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b57a2c1-88f6-49b5-b86c-abf47b2640ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "enw_services = ['FOA', 'WSE']\n",
    "enw_df = compute_combined_reach(weekly_df, enw_services, 'ENW', pop_size_col, country_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc86c21-9fdb-4517-b405-11274afa3364",
   "metadata": {},
   "source": [
    "### ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd687dac-4a47-433e-8015-ec0c2454d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "eng_services = ['GNL', 'WSE']\n",
    "eng_df = compute_combined_reach(weekly_df, eng_services, 'ENG', pop_size_col, country_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37cf81-4ca9-4b91-963c-8eedd95d8358",
   "metadata": {},
   "source": [
    "### EN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5eca40a-1368-4a5f-98ba-77af84438d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "en2_services = ['ENG', 'WOR']\n",
    "en2_df = compute_combined_reach(pd.concat([weekly_df, eng_df]), en2_services, 'EN2', pop_size_col, country_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a9f66-8b84-4e9a-bbd6-fa7fb5f196d0",
   "metadata": {},
   "source": [
    "### AX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd09a33d-9162-4eeb-af02-c3214f2088c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFA missing!\n",
      "AMH missing!\n",
      "DAR missing!\n",
      "IGB missing!\n",
      "KRW missing!\n",
      "PDG missing!\n",
      "TIG missing!\n",
      "YOR missing!\n",
      "UKPS missing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/pq5c3fbj5rs1tz_5w1hycq4h0000gn/T/ipykernel_5863/2379728350.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  africa_df['Reach'] = africa_df.apply(compute_value, axis=1)\n",
      "/Users/brunsd01/BBC Dropbox/Domi Bruns/Audience Insight/GAM 2025/7. GAM25_calculation/3 DigiGAM/code/functions.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df.apply(calculate_formula, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w/c</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>PlaceID</th>\n",
       "      <th>Reach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>AX2</td>\n",
       "      <td>ALG</td>\n",
       "      <td>518320.581417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>AX2</td>\n",
       "      <td>ALG</td>\n",
       "      <td>855570.059536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>AX2</td>\n",
       "      <td>ALG</td>\n",
       "      <td>911421.061368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>AX2</td>\n",
       "      <td>ALG</td>\n",
       "      <td>857463.025015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>AX2</td>\n",
       "      <td>ALG</td>\n",
       "      <td>651868.102728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           w/c ServiceID PlaceID          Reach\n",
       "208 2024-04-01       AX2     ALG  518320.581417\n",
       "209 2024-04-08       AX2     ALG  855570.059536\n",
       "210 2024-04-15       AX2     ALG  911421.061368\n",
       "211 2024-04-22       AX2     ALG  857463.025015\n",
       "212 2024-04-29       AX2     ALG  651868.102728"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['PlaceID', 'digiGAM_FOA_WT-']\n",
    "africa_dedup_countries = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='CountryID')[cols]\n",
    "\n",
    "ax2_services = [\n",
    "    'AFA','AMH','ARA','AZE','BEN','BUR','DAR','ECH','ELT','PER','FRE','GUJ','HAU','HIN','IGB','INO',\n",
    "    'KOR','KRW','KYR','MAN','MAR','NEP','PAS','PDG','POR','PUN','RUS','SER','SIN','SOM','SPA','SWA',\n",
    "    'TAM','TEL','THA','TIG','TUR','UKR','URD','UZB','VIE','YOR', 'FOA', 'UKPS'\n",
    "]\n",
    "\n",
    "ax2_df = weekly_df[weekly_df['ServiceID'].isin(ax2_services)].merge(country_codes, on='PlaceID', how='left')\n",
    "ax2_df = pd.crosstab(\n",
    "                    index = [ ax2_df['PlaceID'], \n",
    "                              ax2_df[pop_size_col], \n",
    "                              ax2_df['w/c'],],\n",
    "                    columns = ax2_df['ServiceID'],\n",
    "                    values =  ax2_df['Reach'],\n",
    "                    aggfunc='sum'\n",
    "                ).reset_index()\n",
    "ax2_df = ax2_df.fillna(0)\n",
    "\n",
    "for col in ax2_services:\n",
    "    if col not in ax2_df.columns:\n",
    "        print(f'{col} missing!')\n",
    "        ax2_df[col] = 0\n",
    "\n",
    "temp2 = ax2_df.merge(africa_dedup_countries, on='PlaceID', how='outer')\n",
    "africa_df = temp2[~temp2['digiGAM_FOA_WT-'].isna()]\n",
    "nonAfrica_df = temp2[temp2['digiGAM_FOA_WT-'].isna()]\n",
    "\n",
    "# Apply the logic row-wise\n",
    "def compute_value(row):\n",
    "    others_sum = sum(row.get(code, 0) for code in ax2_services)\n",
    "    if row['FOA'] > others_sum:\n",
    "        return row['FOA'] + 0.60745497 * others_sum\n",
    "    else:\n",
    "        return others_sum + row['FOA'] * 0.60745497\n",
    "\n",
    "africa_df['Reach'] = africa_df.apply(compute_value, axis=1)\n",
    "nonAfrica_df = functions.sainsbury_formula(nonAfrica_df, 'Population2020', ax2_services, 'Reach')\n",
    "ax2_df = pd.concat([africa_df, nonAfrica_df])\n",
    "ax2_df['ServiceID'] = 'AX2'\n",
    "ax2_df = ax2_df[['w/c', 'ServiceID', 'PlaceID', 'Reach']]\n",
    "\n",
    "ax2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c69bf-cdbd-4a93-aedc-9aac9fc33590",
   "metadata": {},
   "source": [
    "### ANW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67e78e6f-2738-4bdb-8d68-6ca1fed2fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "anw_services = ['AX2', 'WSE']\n",
    "anw_df = compute_combined_reach(pd.concat([weekly_df, ax2_df]), anw_services, 'ANW', \n",
    "                                pop_size_col, country_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423174f-3e21-48aa-bad5-d11a0d484bb7",
   "metadata": {},
   "source": [
    "### ANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec0cee8-820f-46ca-9ebf-7789e6eedb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "any_services = ['ANW', 'GNL']\n",
    "any_df = compute_combined_reach(pd.concat([weekly_df, anw_df]), any_services, 'ANY', \n",
    "                                pop_size_col, country_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9ef4f-ac66-418a-9fac-d6c7570446aa",
   "metadata": {},
   "source": [
    "### TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "679133d5-3318-4fa8-a3ed-24742046d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tot_services = ['ANY', 'MA-']\n",
    "tot_df = compute_combined_reach(pd.concat([weekly_df, any_df]), tot_services, 'TOT', \n",
    "                                pop_size_col, country_codes, calc_type='add')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965198d-6c82-44a0-94cf-0798a5852937",
   "metadata": {},
   "source": [
    "### ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18429caf-725b-4e8c-8e03-ec2ac34addc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_services = ['TOT', 'WOR']\n",
    "all_df = compute_combined_reach(pd.concat([weekly_df, tot_df]), all_services, 'ALL', \n",
    "                                pop_size_col, country_codes, calc_type='add')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a312b1a-bf1c-43c1-852e-371570480770",
   "metadata": {},
   "source": [
    "## finalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4e74290-5854-4706-ab41-efec5e0ccd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weekly_df = pd.concat([weekly_df, weekly_ma_wor_df, \n",
    "                             enw_df, eng_df, en2_df, \n",
    "                             ax2_df, anw_df, any_df, tot_df, all_df])\n",
    "\n",
    "final_weekly_df['PlatformID'] = platformID\n",
    "\n",
    "final_weekly_df.to_csv(f\"../data/combinePlatforms/{gam_info['file_timeinfo']}_weekly_{platformID}.csv\", \n",
    "                       index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296874f3-a17a-4a16-bee0-7b541b96f7f1",
   "metadata": {},
   "source": [
    "# store dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baf440-9c55-4673-b56f-d73c513f3a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gamSessionAutomation)",
   "language": "python",
   "name": "venv_gamsessionautomation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
