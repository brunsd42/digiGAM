{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9049a04-7aeb-470e-b9b7-7c8a8ac3ac75",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38639118-4548-41e4-8289-3e311f2b8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import yxdb\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a2267c-ba2d-443a-a98f-10d3772486d6",
   "metadata": {},
   "source": [
    "## import helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5575b7-60b4-4a6a-866b-0c0be68a197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_GAM2025 import gam_info\n",
    "\n",
    "from functions import execute_sql_query\n",
    "import test_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc37984-f240-4046-a8ec-8f65dbf0d80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAM2025_Lookup.xlsx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_info['lookup_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec311860-8be4-4a7f-a695-b7f6a97570a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Status</th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>Channel URL</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>Linked FB Account</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>active</td>\n",
       "      <td>UCd9maKo3B6jX8pCPzLa2hvA</td>\n",
       "      <td>BBC News မြန်မာ</td>\n",
       "      <td>Burmese</td>\n",
       "      <td>BUR</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAM2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Platform  Status                Channel ID     Channel Name  Service  \\\n",
       "471  Youtube  active  UCd9maKo3B6jX8pCPzLa2hvA  BBC News မြန်မာ  Burmese   \n",
       "\n",
       "    ServiceID      Channel Group Channel URL Channel Username  \\\n",
       "471       BUR  BBC World Service         NaN              NaN   \n",
       "\n",
       "    Linked FB Account     Year  \n",
       "471               NaN  GAM2025  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# country\n",
    "country_codes = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='CountryID')\n",
    "\n",
    "# week \n",
    "week_tester = pd.read_excel(f\"../../{gam_info['lookup_file']}\", sheet_name='GAM Period')\n",
    "week_tester['w/c'] = pd.to_datetime(week_tester['w/c'])\n",
    "week_tester['week_ending'] = pd.to_datetime(week_tester['week_ending'])\n",
    "\n",
    "# social media accounts\n",
    "dtype_dict = {'Channel ID': 'str',\n",
    "              'Linked FB Account': 'str'}\n",
    "socialmedia_accounts = pd.read_excel(f\"../../{gam_info['lookup_file']}\", dtype=dtype_dict,\n",
    "                                     sheet_name='Social Media Accounts new')\n",
    "\n",
    "socialmedia_accounts = socialmedia_accounts[(socialmedia_accounts['Platform'] == 'Youtube')\n",
    "                                            & \n",
    "                                            (socialmedia_accounts['Status'] == 'active')]\n",
    "socialmedia_accounts = socialmedia_accounts.rename(columns={'Excluding UK': 'Channel Group'})\n",
    "\n",
    "channel_ids = socialmedia_accounts['Channel ID'].unique().tolist()\n",
    "formatted_channel_ids = ', '.join(f\"'{channel_id}'\" for channel_id in channel_ids)\n",
    "socialmedia_accounts.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a28163-ac5b-4adb-a45f-289fb847bcbf",
   "metadata": {},
   "source": [
    "# Unique Viewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ccda0-9495-4410-9e98-f56fe7aaaded",
   "metadata": {},
   "source": [
    "## Ingestions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96394a79-cb07-4847-8521-aafec0012689",
   "metadata": {},
   "source": [
    "### automated extracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72f4e43-07b0-46dc-a77f-f86f94cb86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 541.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weeks are present in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 565.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weeks are present in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 572.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weeks are present in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 583.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weeks are present in the dataset.\n",
      "...updating logbook...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_path = f\"../data/raw/YouTube/{gam_info['file_timeinfo']}_export/\"\n",
    "#main_path = f\"../../../../Research Projects/GAM/Digital GAM/2025/Social Media/\"\n",
    "\n",
    "# Dynamically get all folders in the main_path\n",
    "folder_paths = [f for f in os.listdir(main_path) if os.path.isdir(os.path.join(main_path, f))]\n",
    "\n",
    "### TESTING input files ### \n",
    "test_functions.youtube_test_input_files('1_YT_1', folder_paths, main_path, week_tester, test_step='testing automated extracts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7aa60eb-2423-468e-8f7e-d5e5b8e8ed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if files have been previously extracted the unzipping will be skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6240.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6652.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 5287.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 5282.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not change type of impressions click through rate - col does not exist and was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Unique viewers</th>\n",
       "      <th>Engaged views</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Average view duration</th>\n",
       "      <th>w/c</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>source_path</th>\n",
       "      <th>Estimated partner revenue (USD)</th>\n",
       "      <th>week_ending</th>\n",
       "      <th>Impression click-through rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>UC67ak4KkY16efmibaVpqIMQ</td>\n",
       "      <td>U&amp;Yesterday</td>\n",
       "      <td>1285746</td>\n",
       "      <td>40337</td>\n",
       "      <td>76933.0</td>\n",
       "      <td>76933.0</td>\n",
       "      <td>10200.8696</td>\n",
       "      <td>0:07:57</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>BBC Studios</td>\n",
       "      <td>../data/raw/YouTube/GAM2025_export/03 - STChannel 2024-12-02_2024-12-09 BBC Studios.zip</td>\n",
       "      <td>615.63</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Channel ID Channel title  Impressions  Unique viewers  \\\n",
       "6276  UC67ak4KkY16efmibaVpqIMQ   U&Yesterday      1285746           40337   \n",
       "\n",
       "      Engaged views    Views  Watch time (hours) Average view duration  \\\n",
       "6276        76933.0  76933.0          10200.8696               0:07:57   \n",
       "\n",
       "            w/c Channel Group  \\\n",
       "6276 2024-12-02   BBC Studios   \n",
       "\n",
       "                                                                                  source_path  \\\n",
       "6276  ../data/raw/YouTube/GAM2025_export/03 - STChannel 2024-12-02_2024-12-09 BBC Studios.zip   \n",
       "\n",
       "      Estimated partner revenue (USD) week_ending  \\\n",
       "6276                           615.63  2024-12-08   \n",
       "\n",
       "      Impression click-through rate (%)  \n",
       "6276                                  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest files\n",
    "output_csv_path = f\"../data/processed/Youtube/{gam_info['file_timeinfo']}_zipfiles_BBC World Service.csv\"\n",
    "\n",
    "# Check if the output CSV already exists\n",
    "if os.path.exists(output_csv_path):\n",
    "    combined_df = pd.read_csv(output_csv_path)\n",
    "else:\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "# Dynamically get all folders in the main_path\n",
    "folder_paths = [f for f in os.listdir(main_path) if os.path.isdir(os.path.join(main_path, f))]\n",
    "print('if files have been previously extracted the unzipping will be skipped')\n",
    "                \n",
    "for folder in folder_paths:    \n",
    "    for file_name in tqdm(os.listdir(main_path+folder)):\n",
    "        if file_name.endswith('.zip'):\n",
    "                # Check if the file has already been processed\n",
    "                if 'source_path' in combined_df.columns and (main_path+folder + file_name) in combined_df['source_path'].values:\n",
    "                    #print(f\"Skipping {file_name} as it has already been processed.\")\n",
    "                    continue\n",
    "\n",
    "                # TODO next year: advertisement is identified as in each folder is a subfolder total\n",
    "                # and a second subfolder called Advertisment - to process advertisement that has to be added\n",
    "                # as a flag to the individual exports here \n",
    "                with zipfile.ZipFile(os.path.join(main_path+folder, file_name), 'r') as zip_ref:\n",
    "                    for member in zip_ref.namelist():\n",
    "                        if 'Table data.csv' in member:\n",
    "                            with zip_ref.open(member) as file:\n",
    "                                df = pd.read_csv(file)\n",
    "                            \n",
    "                            # Extract start date, end date, and content manager from the file name\n",
    "                            match = re.search(r'(\\d{4}-\\d{2}-\\d{2})_(\\d{4}-\\d{2}-\\d{2}) (.+)', file_name)\n",
    "                            if match:\n",
    "                                df['w/c'] = pd.to_datetime(match.group(1), format='%Y-%m-%d')\n",
    "                                df['Channel Group'] = match.group(3)\n",
    "                                df['source_path'] = main_path+folder + file_name\n",
    "    \n",
    "                            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "                            combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# processing \n",
    "combined_df['w/c'] = pd.to_datetime(combined_df['w/c'], format='ISO8601')\n",
    "combined_df['w/c'] = combined_df['w/c'] - pd.to_timedelta(combined_df['w/c'].dt.weekday, unit='D')\n",
    "\n",
    "combined_df['week_ending'] = combined_df['w/c'] + pd.to_timedelta(6 - combined_df['w/c'].dt.weekday, unit='D')\n",
    "\n",
    "combined_df['Channel Group'] = combined_df['Channel Group'].str.replace('.zip', '')\n",
    "combined_df = combined_df.rename(columns={'Channel': 'Channel ID'})\n",
    "\n",
    "# TODO: confirm what to do with the total (so far it's excluded at the inner join with social media accounts)\n",
    "combined_df = combined_df.loc[combined_df['Channel ID'] != 'Total']\n",
    "\n",
    "# confirm dtypes \n",
    "combined_df.loc[:, 'Unique viewers'] = pd.to_numeric(combined_df['Unique viewers'], errors='raise').astype('Int64')\n",
    "combined_df.loc[:, 'Views'] = pd.to_numeric(combined_df['Views'].fillna(0), errors='raise').astype('Int64')\n",
    "combined_df.loc[:, 'Watch time (hours)'] = pd.to_numeric(combined_df['Watch time (hours)'], errors='raise')\n",
    "\n",
    "# TODO: find out from Minnie why Impressions and Impression click-through rate (%) is not in this dataset -> can be ignored\n",
    "try:\n",
    "    combined_df.loc[:, 'Impressions'] = combined_df['Impressions'].fillna(0)\n",
    "    combined_df.loc[:, 'Impressions'] = pd.to_numeric(combined_df['Impressions'], errors='raise').astype('Int64')\n",
    "except:\n",
    "    print('could not change type of impressions - col does not exist and were created')\n",
    "\n",
    "try:\n",
    "    combined_df.loc[:, 'Impression click-through rate (%)'] = pd.to_numeric(combined_df['Impression click-through rate (%)'], errors='raise')\n",
    "except:\n",
    "    print('could not change type of impressions click through rate - col does not exist and was created')\n",
    "    combined_df.loc[:, 'Impression click-through rate (%)'] = 0\n",
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbb3327-a43a-4e36-b98d-43ceefa53f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Unique viewers</th>\n",
       "      <th>Engaged views</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Average view duration</th>\n",
       "      <th>w/c</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>source_path</th>\n",
       "      <th>Estimated partner revenue (USD)</th>\n",
       "      <th>week_ending</th>\n",
       "      <th>Impression click-through rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>UC16niRr50-MSBwiO3YDb3RA</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>135577389</td>\n",
       "      <td>9915589</td>\n",
       "      <td>15096071.0</td>\n",
       "      <td>15096071.0</td>\n",
       "      <td>483216.3855</td>\n",
       "      <td>0:01:55</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>BBC Global News</td>\n",
       "      <td>../data/raw/YouTube/GAM2025_export/02 - GNChannel 2024-04-01_2024-04-08 BBC Global News.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Channel ID Channel title  Impressions  Unique viewers  \\\n",
       "2449  UC16niRr50-MSBwiO3YDb3RA      BBC News    135577389         9915589   \n",
       "\n",
       "      Engaged views       Views  Watch time (hours) Average view duration  \\\n",
       "2449     15096071.0  15096071.0         483216.3855               0:01:55   \n",
       "\n",
       "            w/c    Channel Group  \\\n",
       "2449 2024-04-01  BBC Global News   \n",
       "\n",
       "                                                                                      source_path  \\\n",
       "2449  ../data/raw/YouTube/GAM2025_export/02 - GNChannel 2024-04-01_2024-04-08 BBC Global News.zip   \n",
       "\n",
       "      Estimated partner revenue (USD) week_ending  \\\n",
       "2449                              NaN  2024-04-07   \n",
       "\n",
       "      Impression click-through rate (%)  \n",
       "2449                                  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[(combined_df['Channel ID'] == 'UC16niRr50-MSBwiO3YDb3RA') & \n",
    "            (combined_df['w/c'] == '2024-04-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4357e-421a-420c-9d5a-1324669825fe",
   "metadata": {},
   "source": [
    "### manual extracts\n",
    "Media Action and channel by channel exports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58504389-df7c-4d06-bce7-99ca398926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: review with minnie for individual exports\n",
    "#because it contains geography or should we use table instead?\n",
    "\n",
    "path = f\"../data/raw/Youtube/{gam_info['file_timeinfo']}_manual/\"\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.xlsx'):  # Assuming the files are excel files\n",
    "        \n",
    "        try:\n",
    "            file_path = os.path.join(path, filename)\n",
    "            df = pd.read_excel(file_path, sheet_name='Totals')\n",
    "            df['Channel ID'] = filename.split('.')[0].split(' - ')[0]\n",
    "            df['Channel title'] = filename.split('.')[0].split(' - ')[0]\n",
    "            df['source_path'] = path+filename\n",
    "            \n",
    "            dataframes.append(df)\n",
    "        except:\n",
    "            print(filename)\n",
    "media_action_df = pd.concat(dataframes)\n",
    "\n",
    "def get_week_dates(date):\n",
    "    if date.weekday() != 6:  # Check if the date is not a Sunday\n",
    "        raise ValueError(\"The input date must be a Sunday.\")\n",
    "    \n",
    "    from_date = date + pd.Timedelta(days=1)  # Monday after the given Sunday\n",
    "    to_date = from_date + pd.Timedelta(days=6)  # Sunday after the Monday\n",
    "    return from_date, to_date\n",
    "\n",
    "media_action_df['Date'] = pd.to_datetime(media_action_df['Date'])\n",
    "\n",
    "# Apply the function to get FromDate and ToDate\n",
    "media_action_df['w/c'], media_action_df['week_ending'] = zip(*media_action_df['Date'].apply(get_week_dates))\n",
    "\n",
    "# Group by Geography, FromDate, ToDate, and filename to sum Views\n",
    "media_action_df = media_action_df.groupby(['w/c', 'week_ending', 'Channel ID', 'Channel title', 'source_path']).agg({'Views': 'sum'}).reset_index()\n",
    "media_action_df['Channel Group'] = 'BBC Media Action'\n",
    "\n",
    "channel_ids = {'Aksi Kita Indonesia': 'aksikitaindo', }\n",
    "media_action_df['Channel ID'] = media_action_df['Channel ID'].replace(channel_ids)\n",
    "\n",
    "media_action_df['Unique viewers'] = media_action_df['Views'] / gam_info['overlap_viewer_uniqueViever']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29b5780-bc5a-427c-8f35-ecbb682cc504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1373"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_info['overlap_viewer_uniqueViever']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc506b-dcc0-45e7-ab67-c9ecec35b094",
   "metadata": {},
   "source": [
    "### combine CMS & non CMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd3cb9e-2927-40f0-9b07-ab531f7f6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7845, 14)\n"
     ]
    }
   ],
   "source": [
    "full_uv_df = pd.concat([combined_df, media_action_df])\n",
    "print(full_uv_df.shape) #(7841, 14)\n",
    "\n",
    "# add service & service code info \n",
    "youtube_uv = full_uv_df.merge(socialmedia_accounts[['Channel ID', 'Channel Name',  'Service', 'ServiceID']], \n",
    "                              on='Channel ID' , how='left')\n",
    "\n",
    "youtube_uv['Unique viewers'] = youtube_uv['Unique viewers'].fillna(0)\n",
    "youtube_uv.drop(columns=['week_ending'], inplace=True)\n",
    "\n",
    "# TODO add test to ensure no data is lost with these \n",
    "#      (and keep on left ot make sure we never loose data)\n",
    "#youtube_uv = youtube_uv.merge(week_tester[['week_ending', 'w/c']], on='week_ending', how='left', indicator=True)\n",
    "#print(youtube_uv._merge.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93816e0-9b7e-45fd-8ed6-8b757bdebe59",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397046e1-808d-45ac-b79b-bcbb4e4a774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...testing Channel ID...\n",
      "Fail - not all elements were retrieved\n",
      "...updating logbook...\n",
      "\n",
      "Missing weeks for each group:\n",
      "     Week Number  YearGAE        w/c week_ending                Channel ID\n",
      "0             14     2025 2024-04-01  2024-04-07  UC3780MVtSV3Huj4si_CQvlQ\n",
      "1             15     2025 2024-04-08  2024-04-14  UC3780MVtSV3Huj4si_CQvlQ\n",
      "2             16     2025 2024-04-15  2024-04-21  UC3780MVtSV3Huj4si_CQvlQ\n",
      "3             17     2025 2024-04-22  2024-04-28  UC3780MVtSV3Huj4si_CQvlQ\n",
      "4             18     2025 2024-04-29  2024-05-05  UC3780MVtSV3Huj4si_CQvlQ\n",
      "..           ...      ...        ...         ...                       ...\n",
      "314            9     2025 2025-02-24  2025-03-02  UCxzzufxh4ILSk6hW5cMMR2w\n",
      "315           10     2025 2025-03-03  2025-03-09  UCxzzufxh4ILSk6hW5cMMR2w\n",
      "316           11     2025 2025-03-10  2025-03-16  UCxzzufxh4ILSk6hW5cMMR2w\n",
      "317           12     2025 2025-03-17  2025-03-23  UCxzzufxh4ILSk6hW5cMMR2w\n",
      "318           13     2025 2025-03-24  2025-03-30  UCxzzufxh4ILSk6hW5cMMR2w\n",
      "\n",
      "[319 rows x 5 columns]\n",
      "...updating logbook...\n",
      "\n",
      "Pass - No combinations occurs more than once a week.\n",
      "...updating logbook...\n",
      "\n",
      "...testing if merge leads to more rows on the metric side\n",
      "pass! :)\n",
      "...updating logbook...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Unique viewers</th>\n",
       "      <th>Engaged views</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Average view duration</th>\n",
       "      <th>w/c</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>source_path</th>\n",
       "      <th>Estimated partner revenue (USD)</th>\n",
       "      <th>Impression click-through rate (%)</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>ServiceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>UCrO5leiEQ2BV2fsy6SWwu7w</td>\n",
       "      <td>BBC Brit South Africa</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>BBC Studios</td>\n",
       "      <td>../data/raw/YouTube/GAM2025_export/03 - STChannel 2024-09-09_2024-09-16 BBC Studios.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBC Brit South Africa</td>\n",
       "      <td>Studios</td>\n",
       "      <td>WOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Channel ID          Channel title  Impressions  \\\n",
       "7324  UCrO5leiEQ2BV2fsy6SWwu7w  BBC Brit South Africa          7.0   \n",
       "\n",
       "      Unique viewers  Engaged views  Views  Watch time (hours)  \\\n",
       "7324             0.0            NaN    0.0                 NaN   \n",
       "\n",
       "     Average view duration        w/c Channel Group  \\\n",
       "7324                   NaN 2024-09-09   BBC Studios   \n",
       "\n",
       "                                                                                  source_path  \\\n",
       "7324  ../data/raw/YouTube/GAM2025_export/03 - STChannel 2024-09-09_2024-09-16 BBC Studios.zip   \n",
       "\n",
       "      Estimated partner revenue (USD)  Impression click-through rate (%)  \\\n",
       "7324                              NaN                                0.0   \n",
       "\n",
       "               Channel Name  Service ServiceID  \n",
       "7324  BBC Brit South Africa  Studios       WOR  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################### Testing ################################### \n",
    "test_step = 'combine CMS & non CMS'\n",
    "# test accounts\n",
    "test_functions.test_filter_elements_returned(youtube_uv, channel_ids, 'Channel ID', \"1_YT_2\", test_step)\n",
    "# test weeks \n",
    "test_functions.test_weeks_presence_per_account('w/c', 'Channel ID', youtube_uv, week_tester, \"1_YT_3\", test_step)\n",
    "# test duplicates\n",
    "cols= ['Channel ID', 'Channel title', 'Channel Group', 'w/c',]\n",
    "test_functions.test_duplicates(youtube_uv, cols, '1_YT_4', test_step)\n",
    "\n",
    "test_functions.test_merge_row_count(youtube_uv, full_uv_df, '1_YT_5', test_step)\n",
    "\n",
    "################################### Testing ################################### \n",
    "\n",
    "youtube_uv.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bb4355-d3b8-4b5d-808e-63be94dfbd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Unique viewers</th>\n",
       "      <th>w/c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Channel ID, Channel Name, ServiceID, Channel Group, Channel title, Unique viewers, w/c]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_uv[youtube_uv['Channel ID'] == 'UCyL1hGLVGqeZ1ak3DJeik7Q']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3100d-e12b-4a61-9f87-dff9cfdb90cb",
   "metadata": {},
   "source": [
    "## Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e5ffc2-04fa-4a99-bb3f-4950a721eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Channel ID', 'Channel Name', 'ServiceID', 'Channel Group',\n",
    "        'Channel title', 'Unique viewers', 'w/c']\n",
    "youtube_uv = youtube_uv[cols]\n",
    "\n",
    "# clean cols \n",
    "youtube_uv['ServiceID'] = youtube_uv['ServiceID'].str.strip().fillna('')\n",
    "youtube_uv['Channel ID'] = youtube_uv['Channel ID'].str.strip().fillna('')\n",
    "youtube_uv['Unique viewers'] = youtube_uv['Unique viewers'].fillna(0)\n",
    "youtube_uv['w/c'] = pd.to_datetime(youtube_uv['w/c'])\n",
    "\n",
    "youtube_uv.to_csv(f\"../data/processed/YouTube/_{gam_info['file_timeinfo']}_uniqueViewer_withAds.csv\", \n",
    "                         index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa0fde-8c4d-4920-8b40-185b8633ae52",
   "metadata": {},
   "source": [
    "## remove Advertising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5e4df9-8aa4-41e2-bd84-b697336cad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Channel Group</th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Unique viewers</th>\n",
       "      <th>w/c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCN7B-QD0Qgn2boVH5Q0pOWg</td>\n",
       "      <td>BBC News Hindi</td>\n",
       "      <td>HIN</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>BBC News Hindi</td>\n",
       "      <td>2.232078e+07</td>\n",
       "      <td>2024-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCiTCB-B_weEmwHk7ifNobQw</td>\n",
       "      <td>BBC News Telugu</td>\n",
       "      <td>TEL</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>BBC News Telugu</td>\n",
       "      <td>4.292848e+06</td>\n",
       "      <td>2024-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC7pluR6rB5KZIbN2IxamzxQ</td>\n",
       "      <td>BBC News Marathi</td>\n",
       "      <td>MAR</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>BBC News Marathi</td>\n",
       "      <td>5.299293e+06</td>\n",
       "      <td>2024-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCb3TZ4SD_Ys3j4z0-8o6auA</td>\n",
       "      <td>BBC News 中文</td>\n",
       "      <td>MAN</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>BBC News 中文</td>\n",
       "      <td>1.968308e+06</td>\n",
       "      <td>2024-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCelk6aHijZq-GJBBB9YpReA</td>\n",
       "      <td>BBC News عربي</td>\n",
       "      <td>ARA</td>\n",
       "      <td>BBC World Service</td>\n",
       "      <td>BBC News عربي</td>\n",
       "      <td>2.618078e+06</td>\n",
       "      <td>2024-06-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Channel ID      Channel Name ServiceID      Channel Group  \\\n",
       "0  UCN7B-QD0Qgn2boVH5Q0pOWg    BBC News Hindi       HIN  BBC World Service   \n",
       "1  UCiTCB-B_weEmwHk7ifNobQw   BBC News Telugu       TEL  BBC World Service   \n",
       "2  UC7pluR6rB5KZIbN2IxamzxQ  BBC News Marathi       MAR  BBC World Service   \n",
       "3  UCb3TZ4SD_Ys3j4z0-8o6auA       BBC News 中文       MAN  BBC World Service   \n",
       "4  UCelk6aHijZq-GJBBB9YpReA     BBC News عربي       ARA  BBC World Service   \n",
       "\n",
       "      Channel title  Unique viewers        w/c  \n",
       "0    BBC News Hindi    2.232078e+07 2024-06-03  \n",
       "1   BBC News Telugu    4.292848e+06 2024-06-03  \n",
       "2  BBC News Marathi    5.299293e+06 2024-06-03  \n",
       "3       BBC News 中文    1.968308e+06 2024-06-03  \n",
       "4     BBC News عربي    2.618078e+06 2024-06-03  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in ad dataset\n",
    "cols = ['Channel', 'Week', '% reach to be removed']\n",
    "youtube_ads = pd.read_excel(f\"../data/raw/Youtube/YouTube_advertising.xlsx\", usecols=cols)\n",
    "youtube_ads.rename(columns={'Channel': 'Channel ID', \n",
    "                            'Week': 'w/c'}, inplace=True)\n",
    "\n",
    "# merge datasetsa\n",
    "youtube_uv_withAds = youtube_uv.merge(youtube_ads, on=['Channel ID', 'w/c'], how='left')\n",
    "youtube_uv_withAds['% reach to be removed'] = youtube_uv_withAds['% reach to be removed'].fillna(0)\n",
    "\n",
    "# subset youtube_uv dataset \n",
    "youtube_uv_organic = youtube_uv_withAds.copy()\n",
    "youtube_uv_organic['Unique viewers'] -= youtube_uv_organic['Unique viewers'].mul(youtube_uv_organic['% reach to be removed'])\n",
    "youtube_uv_organic.drop(columns=['% reach to be removed'], inplace=True)\n",
    "youtube_uv_organic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ecd64-4ab7-4938-955e-0a594a384198",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8700c96b-6011-4ed9-bd08-707773340331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a rough estimate of channel average UV and sort descending by average UV\n",
    "channel_avg_uv = youtube_uv_organic.groupby(['Channel ID', 'ServiceID'])['Unique viewers'].mean()\\\n",
    "                            .reset_index(name='average_UV')\\\n",
    "                            .sort_values(by='average_UV', ascending=False)\n",
    "\n",
    "## TODO make heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29fbf706-0151-46c2-b9fc-7c38f46068cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of unique viewers for each YT Service Code and Week Number\n",
    "sum_uv = youtube_uv_organic.groupby(['ServiceID', 'w/c'])['Unique viewers'].sum()\\\n",
    "                               .reset_index(name='sum_UV')\n",
    "\n",
    "# Calculate the average of unique viewers for each YT Service Code\n",
    "avg_uv = youtube_uv_organic.groupby(['ServiceID'])['Unique viewers'].mean()\\\n",
    "                    .reset_index(name='average_UV')\\\n",
    "                    .sort_values(by='average_UV', ascending=False)\n",
    "\n",
    "## TODO make heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd4d02-e7b3-485e-9f8d-c2a8f0742585",
   "metadata": {},
   "source": [
    "# storing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81d97d2-7627-4f80-8f7f-a374c2c3091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_uv_organic.to_csv(f\"../data/processed/YouTube/{gam_info['file_timeinfo']}_uniqueViewer.csv\", \n",
    "                         index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
